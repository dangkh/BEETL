{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Uqb92Uw_CGL1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pVqcC5ixXU_0"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ifVFfEXSCWfQ"
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from beetl.task_datasets import BeetlSleepTutorial, BeetlSleepSource, BeetlSleepLeaderboard, BeetlMILeaderboard\n",
    "# ds = BeetlSleepSource()\n",
    "# path = ds.download()\n",
    "# print(path)\n",
    "# X, y, info = ds.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeetlSleepLeaderboard().download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FL3ZuKQosAOa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED=997\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "pl.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'max_epochs': 20,\n",
    "    'learning_rate': 0.003,\n",
    "    'weight_decay': 0.01,\n",
    "    'scheduler_patience': 10,\n",
    "    'batch_size': 256,\n",
    "    'dropout_conv': 0.0,\n",
    "    'dropout_fc': 0.1,\n",
    "    'early_stop_patience': 20,\n",
    "    'weight_beta': 0.995\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_distribution(y):\n",
    "    (unique, counts) = np.unique(np.asarray(y), return_counts=True)\n",
    "    frequencies = np.asarray((unique, counts)).T\n",
    "    plt.bar(unique, counts)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(39):\n",
    "#     _, y, _ = dataset.get_data(subjects=[i])\n",
    "#     plot_label_distribution(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P6_OyPmAM0np",
    "outputId": "64e272a9-9544-46a6-fc67-fa3634cae7eb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train, validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data and validation data are from the same set of data and are assumed to be from one distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beetl.task_datasets import BeetlSleepSource\n",
    "dataset = BeetlSleepSource()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, y_train, info = dataset.get_data(subjects=range(0, 35))\n",
    "# X_test, y_test, _ = dataset.get_data(subjects=range(35, 39))\n",
    "\n",
    "X, y, _ = dataset.get_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "IiNTVOfJK5lo",
    "outputId": "3f595d60-c308-4cfe-988a-5dbf8edbdb7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72436, 2, 3000)\n",
      "[[    0 19257]\n",
      " [    1  6470]\n",
      " [    2 28763]\n",
      " [    3  4213]\n",
      " [    4  2400]\n",
      " [    5 11333]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "(unique, counts) = np.unique(np.asarray(y_train), return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "plt.bar(unique, counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00997568, 0.01506863, 0.00873161, 0.01800329, 0.02296356,\n",
       "       0.01209129])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_weight = np.power(hyper_params['weight_beta'], np.sqrt(frequencies[:,1]))\n",
    "loss_weight = (1 - hyper_params['weight_beta']) / (1 - loss_weight)\n",
    "loss_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18109, 2, 3000)\n",
      "[[   0 4786]\n",
      " [   1 1471]\n",
      " [   2 7220]\n",
      " [   3 1034]\n",
      " [   4  657]\n",
      " [   5 2941]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "(unique, counts) = np.unique(np.asarray(y_test), return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "plt.bar(unique, counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.delete(X_train, 1, 1)\n",
    "X_test = np.delete(X_test, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above 2 histograms, we can see that they have similar labels' distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective -f \"^X$\"\n",
    "%reset_selective -f \"^y$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS6FzukMNyby"
   },
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KPNrgRkZN2cE"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class EEG1ChData(Dataset):\n",
    "    def __init__(self, train_data, train_label, mode='train'):\n",
    "        mean = np.mean(train_data, axis=2, keepdims=True)\n",
    "        std = np.std(train_data, axis=2, keepdims=True)\n",
    "        self.X = (train_data - mean) / std\n",
    "        self.y = train_label\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "#             shape = self.X[0].shape\n",
    "#             noise = np.random.normal(0, 0.05, 6000).reshape(shape)\n",
    "#             X = self.X[idx] + noise\n",
    "            # randomly zero out 10 segments of length 50 to 10\n",
    "            X = self.X[idx]\n",
    "            zeroSegCount = np.random.randint(10)\n",
    "            for i in range(zeroSegCount):\n",
    "                s = np.random.randint(3000)\n",
    "                l = np.random.randint(50, 100)\n",
    "                for j in range(s, min(s + l, 3000)):\n",
    "                    X[0][j] = 0\n",
    "        else:\n",
    "            X = self.X[idx]\n",
    "        if self.y is not None:\n",
    "            return torch.tensor(X, dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        else:\n",
    "            return torch.tensor(X, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_a9V9kTN8fk",
    "outputId": "3b54c2b5-1b7c-4587-acb5-3625cc02c7f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72436, 1, 3000)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = EEG1ChData(X_train, y_train)\n",
    "test_dataset = EEG1ChData(X_test, y_test, mode='test')\n",
    "print(train_dataset.X.shape) # should be length, 1, 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12.,  29., 149., 660., 844., 872., 349.,  58.,  15.,  12.]),\n",
       " array([-3.83410592, -3.02822537, -2.22234482, -1.41646427, -0.61058373,\n",
       "         0.19529682,  1.00117737,  1.80705792,  2.61293846,  3.41881901,\n",
       "         4.22469956]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_dataset.X[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_a9V9kTN8fk",
    "outputId": "3b54c2b5-1b7c-4587-acb5-3625cc02c7f4"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    shuffle=True,\n",
    "    batch_size=hyper_params['batch_size'],\n",
    "    pin_memory=True,\n",
    "    num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=hyper_params['batch_size'], pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkLPGnDuM1Oo",
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from pytorch_metric_learning import losses as loss_fn\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    \n",
    "class BaseNet(pl.LightningModule):\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y, torch.tensor(loss_weight, device=self.device, dtype=torch.float))\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'train_acc': torch.sum(torch.argmax(y_hat, axis=1) == y, dtype=torch.float32) / len(y)\n",
    "        }\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['train_acc'] for x in outputs]).mean()\n",
    "        comet_logs = {'train_loss': avg_loss, 'train_acc': avg_acc}\n",
    "        self.log_dict(comet_logs)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        preds = torch.argmax(y_hat, axis=1)\n",
    "        loss = F.cross_entropy(y_hat, y, torch.tensor(loss_weight, device=self.device, dtype=torch.float))\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': torch.sum(preds == y, dtype=torch.float32) / len(y),\n",
    "            'preds': torch.tensor(preds),\n",
    "            'y': torch.tensor(y)\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        comet_logs = {'val_loss': avg_loss, 'val_acc': avg_acc}\n",
    "        \n",
    "        targets = []\n",
    "        predicted = []\n",
    "        for x in outputs:\n",
    "            targets.extend(x['y'])\n",
    "            predicted.extend(x['preds'])\n",
    "            \n",
    "        targets = F.one_hot(torch.tensor(targets))\n",
    "        predicted = F.one_hot(torch.tensor(predicted))\n",
    "        \n",
    "        experiment = self.logger.experiment\n",
    "        experiment.log_confusion_matrix(\n",
    "            targets,\n",
    "            predicted,\n",
    "            title=\"Confusion Matrix, Epoch #%d\" % (self.current_epoch + 1),\n",
    "            file_name=\"confusion-matrix-%03d.json\" % (self.current_epoch + 1),\n",
    "        )\n",
    "        self.log_dict(comet_logs)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return {\n",
    "            'test_loss': loss,\n",
    "            'test_acc': torch.sum(torch.argmax(y_hat, axis=1) == y, dtype=torch.float32) / len(y)\n",
    "        }\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "        comet_logs = {'test_loss': avg_loss, 'test_acc': avg_acc}\n",
    "        self.log_dict(comet_logs)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=self.learning_rate, weight_decay=hyper_params['weight_decay'])\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=hyper_params['scheduler_patience'], min_lr=1e-5),\n",
    "                'interval': 'epoch',\n",
    "                'frequency': 1,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GWbJZMGzMyiM",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "    \n",
    "# class LSTMNet(nn.Module):\n",
    "#     def __init__(self, n_classes):\n",
    "#         super(LSTMNet, self).__init__()\n",
    "#         self.drop1 = nn.Dropout(0.5)\n",
    "#         self.drop_ch = nn.Dropout2d(0.1)\n",
    "#         self.fc = nn.Linear(128, n_classes)\n",
    "#         self.n_classes = n_classes\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=[10, 2], stride=1)\n",
    "#         self.bn1 = nn.BatchNorm1d(16)\n",
    "        \n",
    "#         self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=10, stride=1)\n",
    "#         self.bn2 = nn.BatchNorm1d(32)\n",
    "        \n",
    "#         self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=10, stride=1)\n",
    "#         self.bn3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "#         self.pool = nn.MaxPool1d(4)\n",
    "\n",
    "#         self.lstm = nn.LSTM(input_size=64, hidden_size=128, batch_first=True)\n",
    "\n",
    "#         torch.nn.init.kaiming_normal_(self.conv1.weight)\n",
    "#         torch.nn.init.kaiming_normal_(self.conv2.weight)\n",
    "#         torch.nn.init.kaiming_normal_(self.conv3.weight)\n",
    "#         torch.nn.init.kaiming_normal_(self.fc.weight)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         output = self.bn1(self.pool(F.relu(self.conv1(x)).reshape(x.shape[0], self.conv1.out_channels, -1)))\n",
    "#         output = torch.squeeze(self.drop_ch(torch.unsqueeze(output, 3)))\n",
    "        \n",
    "#         output = self.bn2(self.pool(F.relu(self.conv2(output))))\n",
    "#         output = torch.squeeze(self.drop_ch(torch.unsqueeze(output, 3)))\n",
    "        \n",
    "#         output = self.bn3(self.pool(F.relu(self.conv3(output))))\n",
    "#         output = torch.squeeze(self.drop_ch(torch.unsqueeze(output, 3)))\n",
    "#         # output's shape is batch, 64, 37\n",
    "        \n",
    "#         outputs, _ = self.lstm(torch.transpose(output, 2, 1)) # batch, seq_len, hidden_size\n",
    "# #         _, (outputs, _) = self.lstm(torch.transpose(output, 2, 1)) # batch, seq_len, hidden_size\n",
    "#         output = torch.mean(outputs, 1) # batch, hidden_size\n",
    "# #         output = torch.squeeze(outputs)\n",
    "#         output = F.relu(self.fc(self.drop1(output)))\n",
    "#         return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WvNet(BaseNet):\n",
    "    def __init__(self, learning_rate, drop_conv, drop_fc):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.drop_fc = nn.Dropout(drop_fc)\n",
    "        self.drop_conv = nn.Dropout2d(drop_conv)\n",
    "        self.drop_sm = nn.Dropout(0.33)\n",
    "        self.n_classes = 6\n",
    "        self.conv_f_size = 16\n",
    "        \n",
    "        self.conv_fs = nn.ModuleList()\n",
    "        for i in range(6):\n",
    "            self.conv_fs.append(\n",
    "                    nn.Sequential(OrderedDict([\n",
    "                        ('conv', nn.Conv1d(in_channels=1, out_channels=self.conv_f_size, kernel_size=[5 * (2**i)], stride=1, bias=False)),\n",
    "                        ('act', nn.ReLU()),\n",
    "                        ('pool', nn.AdaptiveAvgPool1d((64))),\n",
    "                        ('bn', nn.BatchNorm1d(self.conv_f_size))\n",
    "                    ])\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.pool_conv_1 = nn.AvgPool2d((2, 2))\n",
    "        self.conv_gr1 = nn.Conv2d(in_channels=len(self.conv_fs), out_channels=16, kernel_size=[3, 7], stride=1, padding=(1, 3), groups=1)\n",
    "        self.bn_gr1 = nn.BatchNorm2d(self.conv_gr1.out_channels)\n",
    "        \n",
    "        self.conv_gr2 = nn.Conv2d(in_channels=self.conv_gr1.out_channels, out_channels=48, kernel_size=[3, 7], stride=1, padding=(1, 3), groups=1)\n",
    "        self.pool_conv_2 = nn.AvgPool2d((2, 1))\n",
    "        self.bn_gr2 = nn.BatchNorm2d(self.conv_gr2.out_channels)\n",
    "        \n",
    "        self.conv_gr3 = nn.Conv2d(in_channels=self.conv_gr2.out_channels, out_channels=128, kernel_size=[4, 8], stride=1, groups=2)\n",
    "        self.bn_gr3 = nn.BatchNorm2d(self.conv_gr3.out_channels)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.conv_gr3.out_channels, hidden_size=64, bidirectional=True, batch_first=True)\n",
    "#         self.fc2 = nn.Linear(48, self.n_classes)\n",
    "        \n",
    "#         self.fc = nn.Linear(128, self.n_classes)\n",
    "#         self.fc1 = nn.Linear(128, 48)\n",
    "#\n",
    "        # depthwise convolution acts as FC layer\n",
    "        self.dw_conv = nn.Conv1d(in_channels=128, out_channels=6, kernel_size=[1], stride=1)\n",
    "\n",
    "        \n",
    "        for conv_f in self.conv_fs:\n",
    "            torch.nn.init.kaiming_normal_(conv_f.conv.weight)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_gr1.weight)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_gr2.weight)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_gr3.weight)\n",
    "        torch.nn.init.kaiming_normal_(self.dw_conv.weight)\n",
    "#         torch.nn.init.kaiming_normal_(self.fc1.weight)\n",
    "#         torch.nn.init.kaiming_normal_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for i in range(len(self.conv_fs)):\n",
    "            output = self.conv_fs[i](x)\n",
    "            output = self.drop_conv(output)\n",
    "            output = torch.squeeze(output)\n",
    "            outputs.append(output)\n",
    "        \n",
    "        output = torch.stack((outputs), dim=1)\n",
    "        \n",
    "        output = self.bn_gr1(self.pool_conv_1(F.relu(self.conv_gr1(output))))\n",
    "        output = self.drop_conv(output)\n",
    "        \n",
    "        output = self.bn_gr2(self.pool_conv_2(F.relu(self.conv_gr2(output))))\n",
    "        output = self.drop_conv(output)\n",
    "        \n",
    "        output = self.bn_gr3(F.relu(self.conv_gr3(output)))\n",
    "        output = torch.squeeze(output)\n",
    "        \n",
    "#         _, (outputs, _) = self.lstm(torch.transpose(output, 2, 1)) # batch, seq_len, hidden_size\n",
    "#         output = outputs[1] # get hidden of backward pass\n",
    "\n",
    "        outputs, _ = self.lstm(torch.transpose(output, 2, 1)) # batch, seq_len, hidden_size\n",
    "        outputs = self.dw_conv(torch.transpose(outputs, 2, 1))\n",
    "        output = torch.mean(outputs, dim=2) # batch, 6\n",
    "\n",
    "#         output = F.relu(self.fc1(self.drop_fc(output)))\n",
    "#         output = self.fc2(self.drop_fc(output))\n",
    "        return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=self.learning_rate, weight_decay=hyper_params['weight_decay'])\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': lr_scheduler.OneCycleLR(optimizer, max_lr=hyper_params['learning_rate'], steps_per_epoch=len(train_loader), epochs=hyper_params['max_epochs'], pct_start=0.3, div_factor=3),\n",
    "                'interval': 'step',\n",
    "                'frequency': 1,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torch.optim import lr_scheduler\n",
    "# from pytorch_metric_learning import losses as loss_fn\n",
    "# from collections import OrderedDict\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    \n",
    "# class WvConvNet(pl.LightningModule):\n",
    "#     def __init__(self, learning_rate):\n",
    "#         super().__init__()\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.drop_fc = nn.Dropout(0.2)\n",
    "#         self.drop_conv = nn.Dropout2d(0.1)\n",
    "#         self.n_classes = 6\n",
    "#         self.conv_f_size = 16\n",
    "        \n",
    "#         self.conv_fs = nn.ModuleList()\n",
    "#         for i in range(6):\n",
    "#             self.conv_fs.append(\n",
    "#                     nn.Sequential(OrderedDict([\n",
    "#                         ('conv', nn.Conv2d(in_channels=1, out_channels=self.conv_f_size, kernel_size=[4, 2], stride=1, dilation=(2**i, 1), bias=False)),\n",
    "#                         ('act', nn.ReLU()),\n",
    "#                         ('pool', nn.AdaptiveAvgPool2d((32, 1))),\n",
    "#                         ('bn', nn.BatchNorm2d(self.conv_f_size))\n",
    "#                     ])\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#         self.pool_conv_2d = nn.MaxPool2d((2, 2))\n",
    "#         self.conv_gr1 = nn.Conv2d(in_channels=len(self.conv_fs), out_channels=32, kernel_size=[3, 7], stride=1, padding=(1, 3), groups=2)\n",
    "#         self.bn_gr1 = nn.BatchNorm2d(self.conv_gr1.out_channels)\n",
    "        \n",
    "#         self.conv_gr2 = nn.Conv2d(in_channels=self.conv_gr1.out_channels, out_channels=64, kernel_size=[3, 7], stride=1, padding=(1, 3), groups=2)\n",
    "#         self.bn_gr2 = nn.BatchNorm2d(self.conv_gr2.out_channels)\n",
    "        \n",
    "#         self.conv_gr3 = nn.Conv2d(in_channels=self.conv_gr2.out_channels, out_channels=128, kernel_size=[4, 8], stride=1, groups=2)\n",
    "#         self.bn_gr3 = nn.BatchNorm2d(self.conv_gr3.out_channels)\n",
    "        \n",
    "#         self.fc = nn.Linear(self.conv_gr3.out_channels, self.n_classes)\n",
    "    \n",
    "#         for conv_f in self.conv_fs:\n",
    "#             torch.nn.init.kaiming_normal_(conv_f.conv.weight)\n",
    "#         torch.nn.init.kaiming_normal_(self.conv_gr1.weight)\n",
    "#         torch.nn.init.kaiming_normal_(self.conv_gr2.weight)\n",
    "#         torch.nn.init.kaiming_normal_(self.conv_gr3.weight)\n",
    "#         torch.nn.init.kaiming_normal_(self.fc.weight)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         n_batch = x.shape[0]\n",
    "#         outputs = []\n",
    "#         for i in range(len(self.conv_fs)):\n",
    "#             output = self.conv_fs[i](x)\n",
    "#             output = self.drop_conv(output)\n",
    "#             output = torch.squeeze(output)\n",
    "#             outputs.append(output)\n",
    "        \n",
    "#         output = torch.stack((outputs), dim=1)\n",
    "        \n",
    "#         output = self.bn_gr1(self.pool_conv_2d(F.relu(self.conv_gr1(output))))\n",
    "#         output = self.drop_conv(output)\n",
    "        \n",
    "#         output = self.bn_gr2(self.pool_conv_2d(F.relu(self.conv_gr2(output))))\n",
    "#         output = self.drop_conv(output)\n",
    "        \n",
    "#         output = self.bn_gr3(F.relu(self.conv_gr3(output)))\n",
    "#         output = self.drop_fc(torch.squeeze(output))\n",
    "\n",
    "#         output = self.fc(output)\n",
    "#         return output\n",
    "    \n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         y_hat = self(x)\n",
    "#         loss = F.cross_entropy(y_hat, y)\n",
    "#         return {\n",
    "#             'loss': loss,\n",
    "#             'train_acc': torch.sum(torch.argmax(y_hat, axis=1) == y, dtype=torch.float32) / len(y)\n",
    "#         }\n",
    "    \n",
    "#     def training_epoch_end(self, outputs):\n",
    "#         avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "#         avg_acc = torch.stack([x['train_acc'] for x in outputs]).mean()\n",
    "#         comet_logs = {'train_loss': avg_loss, 'train_acc': avg_acc}\n",
    "#         self.log_dict(comet_logs)\n",
    "    \n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         y_hat = self(x)\n",
    "#         preds = torch.argmax(y_hat, axis=1)\n",
    "#         loss = F.cross_entropy(y_hat, y)\n",
    "#         return {\n",
    "#             'val_loss': loss,\n",
    "#             'val_acc': torch.sum(preds == y, dtype=torch.float32) / len(y),\n",
    "#         }\n",
    "\n",
    "#     def validation_epoch_end(self, outputs):\n",
    "#         avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "#         avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "#         comet_logs = {'val_loss': avg_loss, 'val_acc': avg_acc}\n",
    "#         self.log_dict(comet_logs)\n",
    "    \n",
    "#     def test_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         y_hat = self(x)\n",
    "#         loss = F.cross_entropy(y_hat, y)\n",
    "#         return {\n",
    "#             'test_loss': loss,\n",
    "#             'test_acc': torch.sum(torch.argmax(y_hat, axis=1) == y, dtype=torch.float32) / len(y)\n",
    "#         }\n",
    "    \n",
    "#     def test_epoch_end(self, outputs):\n",
    "#         avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "#         avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "#         comet_logs = {'test_loss': avg_loss, 'test_acc': avg_acc}\n",
    "#         self.log_dict(comet_logs)\n",
    "    \n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = optim.Adam(model.parameters(), lr=self.learning_rate, weight_decay=hyper_params['weight_decay'])\n",
    "#         return {\n",
    "#             'optimizer': optimizer,\n",
    "#             'lr_scheduler': {\n",
    "#                 'scheduler': lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=hyper_params['scheduler_patience'], min_lr=1e-6),\n",
    "#                 'interval': 'epoch',\n",
    "#                 'frequency': 1,\n",
    "#                 'monitor': 'val_loss',\n",
    "#             }\n",
    "#         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in online mode\n",
      "/home/peara/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:360: UserWarning: Checkpoint directory ../models/ exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import CometLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# arguments made to CometLogger are passed on to the comet_ml.Experiment class\n",
    "comet_logger = CometLogger(\n",
    "    api_key=comet_config['api_key'],\n",
    "    workspace=comet_config['workspace'],\n",
    "    project_name=comet_config['project_name'],\n",
    "    experiment_name='WvNet f 1 channel + 5 * (2**i), len 64 + 3 layer + 16 features + lstm + dw_conv + random cut + weighted loss'\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=hyper_params['early_stop_patience'],\n",
    "    min_delta=0.0005,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='../models/',\n",
    "    filename='wvnet-1ch-{epoch}-{val_loss:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=hyper_params['max_epochs'], logger=comet_logger, deterministic=True, callbacks=[lr_monitor, checkpoint_callback], stochastic_weight_avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/peara/sleep-eeg/a276306868f74d2e8c710378cad3569b\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.logger.log_hyperparams(hyper_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = WvNet(hyper_params['learning_rate'], hyper_params['dropout_conv'], hyper_params['dropout_fc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "COMET WARNING: Empty mapping given to log_params({}); ignoring\n",
      "\n",
      "   | Name        | Type        | Params\n",
      "---------------------------------------------\n",
      "0  | drop_fc     | Dropout     | 0     \n",
      "1  | drop_conv   | Dropout2d   | 0     \n",
      "2  | drop_sm     | Dropout     | 0     \n",
      "3  | conv_fs     | ModuleList  | 5.2 K \n",
      "4  | pool_conv_1 | AvgPool2d   | 0     \n",
      "5  | conv_gr1    | Conv2d      | 2.0 K \n",
      "6  | bn_gr1      | BatchNorm2d | 32    \n",
      "7  | conv_gr2    | Conv2d      | 16.2 K\n",
      "8  | pool_conv_2 | AvgPool2d   | 0     \n",
      "9  | bn_gr2      | BatchNorm2d | 96    \n",
      "10 | conv_gr3    | Conv2d      | 98.4 K\n",
      "11 | bn_gr3      | BatchNorm2d | 256   \n",
      "12 | lstm        | LSTM        | 99.3 K\n",
      "13 | dw_conv     | Conv1d      | 774   \n",
      "---------------------------------------------\n",
      "222 K     Trainable params\n",
      "0         Non-trainable params\n",
      "222 K     Total params\n",
      "0.889     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peara/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "<ipython-input-26-610d57336b04>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'preds': torch.tensor(preds),\n",
      "<ipython-input-26-610d57336b04>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'y': torch.tensor(y)\n",
      "Global seed set to 997\n",
      "/home/peara/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a12de516a4428da9b38ed90bbc6d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peara/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py:100: LightningDeprecationWarning: The signature of `Callback.on_train_epoch_end` has changed in v1.3. `outputs` parameter has been removed. Support for the old signature will be removed in v1.5\n",
      "  warning_cache.deprecation(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peara/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/stochastic_weight_avg.py:199: UserWarning: SWA is currently only supported every epoch. Found {'scheduler': <torch.optim.lr_scheduler.OneCycleLR object at 0x7fceec251730>, 'name': None, 'interval': 'step', 'frequency': 1, 'reduce_on_plateau': False, 'monitor': 'val_loss', 'strict': True, 'opt_idx': None}\n",
      "  rank_zero_warn(f\"SWA is currently only supported every epoch. Found {scheduler_cfg}\")\n",
      "Swapping scheduler <torch.optim.lr_scheduler.OneCycleLR object at 0x7fceec251730> for <torch.optim.swa_utils.SWALR object at 0x7fcfe2a0c8b0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/peara/sleep-eeg/a276306868f74d2e8c710378cad3569b\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     loss [1132]     : (0.28463658690452576, 1.5725730657577515)\n",
      "COMET INFO:     lr-AdamW [21]   : (0.0008481747167074296, 0.002999999528461056)\n",
      "COMET INFO:     train_acc [21]  : (0.7123841047286987, 0.8576430678367615)\n",
      "COMET INFO:     train_loss [21] : (0.3973385989665985, 0.7945191264152527)\n",
      "COMET INFO:     val_acc [21]    : (0.7655301094055176, 0.8193902969360352)\n",
      "COMET INFO:     val_loss [21]   : (0.516021192073822, 0.64830482006073)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name : WvNet f 1 channel + 5 * (2**i), len 64 + 3 layer + 16 features + lstm + dw_conv + random cut + weighted loss\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     batch_size          : 256\n",
      "COMET INFO:     dropout_conv        : 1\n",
      "COMET INFO:     dropout_fc          : 0.1\n",
      "COMET INFO:     early_stop_patience : 20\n",
      "COMET INFO:     learning_rate       : 0.003\n",
      "COMET INFO:     max_epochs          : 20\n",
      "COMET INFO:     scheduler_patience  : 10\n",
      "COMET INFO:     weight_beta         : 0.995\n",
      "COMET INFO:     weight_decay        : 0.01\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     confusion-matrix         : 22\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (846 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
      "COMET INFO: Still uploading 4 file(s)\n",
      "COMET INFO: Still uploading 2 file(s)\n",
      "COMET INFO: Still uploading 2 file(s)\n",
      "COMET INFO: Still uploading 2 file(s)\n",
      "COMET INFO: Still uploading 1 file(s)\n",
      "COMET INFO: Still uploading 1 file(s)\n",
      "COMET INFO: Still uploading 1 file(s)\n",
      "COMET INFO: Still uploading 1 file(s)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reset_selective -f \"^train_loader$\"\n",
    "%reset_selective -f \"^train_dataset$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective -f \"^test_loader$\"\n",
    "%reset_selective -f \"^test_dataset$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Test data is from a different set of subjects and have a different distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from beetl.task_datasets import BeetlSleepLeaderboard\n",
    "X_sleep_target, y_sleep_target, _, _ = BeetlSleepLeaderboard().get_data(subjects=range(0, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15442, 1, 3000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_sleep_target = np.delete(X_sleep_target, 1, 1)\n",
    "print(X_sleep_target.shape)\n",
    "(unique, counts) = np.unique(y_sleep_target, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "ynecnk8ab1my"
   },
   "outputs": [],
   "source": [
    "transfer_dataset = EEG1ChData(X_sleep_target, y_sleep_target, mode='test')\n",
    "transfer_loader = torch.utils.data.DataLoader(dataset=transfer_dataset, batch_size=hyper_params['batch_size'], pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/peara/sleep-eeg/a276306868f74d2e8c710378cad3569b\n",
      "\n",
      "/home/peara/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f7b57de86242d59d39a70110e940e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.7423436641693115, 'test_loss': 0.6673266887664795}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6673266887664795, 'test_acc': 0.7423436641693115}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, transfer_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: -----------------------------------\n",
      "COMET INFO: Comet.ml ExistingExperiment Summary\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/peara/sleep-eeg/a276306868f74d2e8c710378cad3569b\n",
      "COMET INFO:   Metrics:\n",
      "COMET INFO:     test_acc  : 0.7423436641693115\n",
      "COMET INFO:     test_loss : 0.6673266887664795\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name : WvNet f 1 channel + 5 * (2**i), len 64 + 3 layer + 16 features + lstm + dw_conv + random cut + weighted loss\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     model graph : 1\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "trainer.logger.experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective -f \"^transfer_loader$\"\n",
    "%reset_selective -f \"^transfer_dataset$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = model.conv_fs[0].conv.weight[2][0].cpu().detach().numpy()\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "t, y = signal.impulse(([1.0], f))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"../models/wvnet.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsNlUvv9ck56"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beetl.task_datasets import BeetlSleepLeaderboard\n",
    "_, _, X_sleep_test, _ = BeetlSleepLeaderboard().get_data(subjects=range(6, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sleep_test = np.delete(X_sleep_test, 1, 1)\n",
    "submission_dataset = EEG1ChData(X_sleep_test, None, mode='test')\n",
    "submission_loader = torch.utils.data.DataLoader(dataset=submission_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WvNet.load_from_checkpoint(CHECKPOINT_PATH, learning_rate=0.01, drop_conv=0, drop_fc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/peara/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, predict dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bb26b98dfd43329fb0b9834207a7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicts = trainer.predict(model, submission_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for predicts in predicts:\n",
    "    predicted_labels.extend(np.argmax(predicts.cpu().detach().numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 2, 2, 1, 2, 0, 1, 2, 2, 2, 2, 5, 1, 0, 5, 2, 2, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels[:20])\n",
    "np.savetxt(\"answer.txt\",predicted_labels,delimiter=',',fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25748\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_label_distribution(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of NIP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
